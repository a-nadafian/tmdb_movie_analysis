{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Anatomy of a Blockbuster\n",
    "\n",
    "## 1. Data Wrangling and EDA\n",
    "\n",
    "This notebook preprocesses the TMDB 5000 movie dataset. The goal is to clean the data and prepare it for analysis, with a focus on understanding the relationship between a movie's budget, revenue, and genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the datasets\n",
    "try:\n",
    "    movies_df = pd.read_csv('../data/raw/tmdb_5000_movies.csv')\n",
    "    credits_df = pd.read_csv('../data/raw/tmdb_5000_credits.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset files not found in data/raw/. Please ensure the files are there.\")\n",
    "    # Create empty dataframes to avoid further errors in notebook execution\n",
    "    movies_df = pd.DataFrame()\n",
    "    credits_df = pd.DataFrame()\n",
    "\n",
    "# Merge the two dataframes\n",
    "if not movies_df.empty and not credits_df.empty:\n",
    "    # Rename the 'id' column in movies_df to 'movie_id' to match credits_df for merging\n",
    "    credits_df.rename(columns={'movie_id': 'id'}, inplace=True)\n",
    "    df = pd.merge(credits_df, movies_df, on='id')\n",
    "    print(\"Datasets loaded and merged successfully.\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"Could not load or merge data. Please check the file paths and data integrity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Initial Data Cleaning\n",
    "\n",
    "In this section, we perform some initial data cleaning, such as handling missing values and correcting data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's get a sense of the missing data in the dataframe.\n",
    "if 'df' in locals() and not df.empty:\n",
    "    print(\"Missing values before cleaning:\")\n",
    "    display(df.isnull().sum())\n",
    "\n",
    "    # Replace 0s with NaN in budget and revenue columns, as 0 is likely missing data\n",
    "    df['budget'] = df['budget'].replace(0, np.nan)\n",
    "    df['revenue'] = df['revenue'].replace(0, np.nan)\n",
    "\n",
    "    # Drop rows where 'release_date' is missing, as it's crucial for time-based analysis\n",
    "    df.dropna(subset=['release_date'], inplace=True)\n",
    "\n",
    "    # Convert 'release_date' to datetime objects\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "\n",
    "    print(\"\\nMissing values after cleaning 0s in budget/revenue and dropping rows with null release_date:\")\n",
    "    display(df.isnull().sum())\n",
    "    \n",
    "    # We will handle the remaining missing values later\n",
    "else:\n",
    "    print(\"DataFrame `df` not available. Skipping initial data cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Clean and Transform Complex Columns\n",
    "\n",
    "Several columns in the dataset are stored as JSON-like strings. We need to parse these columns to extract the relevant information. We'll focus on `genres`, `keywords`, `cast`, and `crew`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def parse_json_col(column):\n",
    "    \"\"\"\n",
    "    Parses a JSON-like column to extract the 'name' from each object in the list.\n",
    "    \"\"\"\n",
    "    if 'df' in locals() and not df.empty:\n",
    "        # ast.literal_eval is a safe way to evaluate a string containing a Python literal\n",
    "        # Here, we handle potential missing values (floats) by returning an empty list\n",
    "        return column.apply(lambda x: [i['name'] for i in ast.literal_eval(x)] if isinstance(x, str) else [])\n",
    "    return pd.Series() # Return empty series if df is not available\n",
    "\n",
    "def get_director(crew):\n",
    "    \"\"\"\n",
    "    Parses the crew column to extract the director's name.\n",
    "    \"\"\"\n",
    "    if 'df' in locals() and not df.empty:\n",
    "        if isinstance(crew, str):\n",
    "            for member in ast.literal_eval(crew):\n",
    "                if member['job'] == 'Director':\n",
    "                    return member['name']\n",
    "    return np.nan # Return NaN if no director is found\n",
    "\n",
    "if 'df' in locals() and not df.empty:\n",
    "    # Parse genres and keywords\n",
    "    df['genres'] = parse_json_col(df['genres'])\n",
    "    df['keywords'] = parse_json_col(df['keywords'])\n",
    "    \n",
    "    # Parse cast - let's take top 3 actors\n",
    "    df['cast'] = df['cast'].apply(lambda x: [i['name'] for i in ast.literal_eval(x)[:3]] if isinstance(x, str) else [])\n",
    "    \n",
    "    # Parse crew to get the director\n",
    "    df['director'] = df['crew'].apply(get_director)\n",
    "\n",
    "    # Now we can drop the original 'crew' column as we've extracted what we need\n",
    "    df.drop(columns=['crew'], inplace=True)\n",
    "    \n",
    "    print(\"Cleaned 'genres', 'keywords', 'cast', and extracted 'director'.\")\n",
    "    display(df[['title', 'genres', 'keywords', 'cast', 'director']].head())\n",
    "else:\n",
    "    print(\"DataFrame `df` not available. Skipping complex column cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Feature Engineering\n",
    "\n",
    "Now that the data is cleaner, we can create new features that might be useful for our analysis. We'll extract time-based features from `release_date` and create profitability metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals() and not df.empty:\n",
    "    # Extract year, month, and day from release_date\n",
    "    df['release_year'] = df['release_date'].dt.year\n",
    "    df['release_month'] = df['release_date'].dt.month\n",
    "    df['release_day'] = df['release_date'].dt.day\n",
    "    \n",
    "    # Calculate profit and return on investment (ROI)\n",
    "    # We will only calculate this where both budget and revenue are available\n",
    "    df['profit'] = df['revenue'] - df['budget']\n",
    "    df['roi'] = (df['profit'] / df['budget']) * 100\n",
    "    \n",
    "    print(\"Created new features: 'release_year', 'release_month', 'release_day', 'profit', 'roi'.\")\n",
    "    display(df[['title', 'release_date', 'release_year', 'budget', 'revenue', 'profit', 'roi']].head())\n",
    "else:\n",
    "    print(\"DataFrame `df` not available. Skipping feature engineering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section, we'll explore the cleaned dataset to uncover initial insights and answer some of our key research questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals() and not df.empty:\n",
    "    print(\"Summary statistics for numerical columns:\")\n",
    "    display(df.describe())\n",
    "else:\n",
    "    print(\"DataFrame `df` not available. Skipping EDA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Budget vs. Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals() and not df.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.scatterplot(data=df, x='budget', y='revenue', alpha=0.5)\n",
    "    plt.title('Budget vs. Revenue')\n",
    "    plt.xlabel('Budget (in hundred millions)')\n",
    "    plt.ylabel('Revenue (in billions)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"DataFrame `df` not available. Skipping Budget vs. Revenue plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Genre Profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals() and not df.empty:\n",
    "    # Explode the genres list to have one genre per row\n",
    "    genres_df = df.explode('genres')\n",
    "    \n",
    "    # Calculate the median profit per genre\n",
    "    genre_profit = genres_df.groupby('genres')['profit'].median().sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x=genre_profit.values, y=genre_profit.index, orient='h')\n",
    "    plt.title('Median Profit by Genre')\n",
    "    plt.xlabel('Median Profit (in hundred millions)')\n",
    "    plt.ylabel('Genre')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"DataFrame `df` not available. Skipping Genre Profitability plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Top 10 Most Profitable Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals() and not df.empty:\n",
    "    # Sort by profit and get the top 10\n",
    "    top_10_profitable = df.sort_values(by='profit', ascending=False).head(10)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=top_10_profitable, x='profit', y='title', orient='h')\n",
    "    plt.title('Top 10 Most Profitable Movies')\n",
    "    plt.xlabel('Profit (in billions)')\n",
    "    plt.ylabel('Movie Title')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"DataFrame `df` not available. Skipping Top 10 Profitable Movies plot.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
